{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import scipy.io  \n",
    "import argparse\n",
    "import datetime\n",
    "import struct\n",
    "import string\n",
    "import random\n",
    "import errno\n",
    "import time                       \n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils for building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_type = 'avg'\n",
    "\n",
    "def conv_layer(layer_name, layer_input, W):\n",
    "    conv = tf.nn.conv2d(layer_input, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    if True: print('--{} | shape={} | weights_shape={}'.format(layer_name, \n",
    "        conv.get_shape(), W.get_shape()))\n",
    "    return conv\n",
    "\n",
    "def relu_layer(layer_name, layer_input, b):\n",
    "    relu = tf.nn.relu(layer_input + b)\n",
    "    return relu\n",
    "\n",
    "def pool_layer(layer_name, layer_input):\n",
    "    if pooling_type == 'avg':\n",
    "        pool = tf.nn.avg_pool(layer_input, ksize=[1, 2, 2, 1], \n",
    "            strides=[1, 2, 2, 1], padding='SAME')\n",
    "    elif pooling_type == 'max':\n",
    "        pool = tf.nn.max_pool(layer_input, ksize=[1, 2, 2, 1], \n",
    "            strides=[1, 2, 2, 1], padding='SAME')\n",
    "    return pool\n",
    "\n",
    "def get_weights(vgg_layers, i):\n",
    "    weights = vgg_layers[i][0][0][2][0][0]\n",
    "    W = tf.constant(weights)\n",
    "    return W\n",
    "\n",
    "def get_bias(vgg_layers, i):\n",
    "    bias = vgg_layers[i][0][0][2][0][1]\n",
    "    b = tf.constant(np.reshape(bias, (bias.size)))\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to build the vgg19 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_img):\n",
    "    if True: print('\\nBUILDING VGG-19 NETWORK')\n",
    "    net = {}\n",
    "    _, h, w, d     = input_img.shape\n",
    "\n",
    "    if True: print('loading model weights...')\n",
    "    vgg_rawnet     = scipy.io.loadmat('imagenet-vgg-verydeep-19.mat')\n",
    "    vgg_layers     = vgg_rawnet['layers'][0]\n",
    "    if True: print('constructing layers...')\n",
    "    net['input']   = tf.Variable(np.zeros((1, h, w, d), dtype=np.float32))\n",
    "\n",
    "    if True: print('LAYER GROUP 1')\n",
    "    net['conv1_1'] = conv_layer('conv1_1', net['input'], W=get_weights(vgg_layers, 0))\n",
    "    net['relu1_1'] = relu_layer('relu1_1', net['conv1_1'], b=get_bias(vgg_layers, 0))\n",
    "\n",
    "    net['conv1_2'] = conv_layer('conv1_2', net['relu1_1'], W=get_weights(vgg_layers, 2))\n",
    "    net['relu1_2'] = relu_layer('relu1_2', net['conv1_2'], b=get_bias(vgg_layers, 2))\n",
    "\n",
    "    net['pool1']   = pool_layer('pool1', net['relu1_2'])\n",
    "\n",
    "    if True: print('LAYER GROUP 2')  \n",
    "    net['conv2_1'] = conv_layer('conv2_1', net['pool1'], W=get_weights(vgg_layers, 5))\n",
    "    net['relu2_1'] = relu_layer('relu2_1', net['conv2_1'], b=get_bias(vgg_layers, 5))\n",
    "\n",
    "    net['conv2_2'] = conv_layer('conv2_2', net['relu2_1'], W=get_weights(vgg_layers, 7))\n",
    "    net['relu2_2'] = relu_layer('relu2_2', net['conv2_2'], b=get_bias(vgg_layers, 7))\n",
    "\n",
    "    net['pool2']   = pool_layer('pool2', net['relu2_2'])\n",
    "\n",
    "    if True: print('LAYER GROUP 3')\n",
    "    net['conv3_1'] = conv_layer('conv3_1', net['pool2'], W=get_weights(vgg_layers, 10))\n",
    "    net['relu3_1'] = relu_layer('relu3_1', net['conv3_1'], b=get_bias(vgg_layers, 10))\n",
    "\n",
    "    net['conv3_2'] = conv_layer('conv3_2', net['relu3_1'], W=get_weights(vgg_layers, 12))\n",
    "    net['relu3_2'] = relu_layer('relu3_2', net['conv3_2'], b=get_bias(vgg_layers, 12))\n",
    "\n",
    "    net['conv3_3'] = conv_layer('conv3_3', net['relu3_2'], W=get_weights(vgg_layers, 14))\n",
    "    net['relu3_3'] = relu_layer('relu3_3', net['conv3_3'], b=get_bias(vgg_layers, 14))\n",
    "\n",
    "    net['conv3_4'] = conv_layer('conv3_4', net['relu3_3'], W=get_weights(vgg_layers, 16))\n",
    "    net['relu3_4'] = relu_layer('relu3_4', net['conv3_4'], b=get_bias(vgg_layers, 16))\n",
    "\n",
    "    net['pool3']   = pool_layer('pool3', net['relu3_4'])\n",
    "\n",
    "    if True: print('LAYER GROUP 4')\n",
    "    net['conv4_1'] = conv_layer('conv4_1', net['pool3'], W=get_weights(vgg_layers, 19))\n",
    "    net['relu4_1'] = relu_layer('relu4_1', net['conv4_1'], b=get_bias(vgg_layers, 19))\n",
    "\n",
    "    net['conv4_2'] = conv_layer('conv4_2', net['relu4_1'], W=get_weights(vgg_layers, 21))\n",
    "    net['relu4_2'] = relu_layer('relu4_2', net['conv4_2'], b=get_bias(vgg_layers, 21))\n",
    "\n",
    "    net['conv4_3'] = conv_layer('conv4_3', net['relu4_2'], W=get_weights(vgg_layers, 23))\n",
    "    net['relu4_3'] = relu_layer('relu4_3', net['conv4_3'], b=get_bias(vgg_layers, 23))\n",
    "\n",
    "    net['conv4_4'] = conv_layer('conv4_4', net['relu4_3'], W=get_weights(vgg_layers, 25))\n",
    "    net['relu4_4'] = relu_layer('relu4_4', net['conv4_4'], b=get_bias(vgg_layers, 25))\n",
    "\n",
    "    net['pool4']   = pool_layer('pool4', net['relu4_4'])\n",
    "\n",
    "    if True: print('LAYER GROUP 5')\n",
    "    net['conv5_1'] = conv_layer('conv5_1', net['pool4'], W=get_weights(vgg_layers, 28))\n",
    "    net['relu5_1'] = relu_layer('relu5_1', net['conv5_1'], b=get_bias(vgg_layers, 28))\n",
    "\n",
    "    net['conv5_2'] = conv_layer('conv5_2', net['relu5_1'], W=get_weights(vgg_layers, 30))\n",
    "    net['relu5_2'] = relu_layer('relu5_2', net['conv5_2'], b=get_bias(vgg_layers, 30))\n",
    "\n",
    "    net['conv5_3'] = conv_layer('conv5_3', net['relu5_2'], W=get_weights(vgg_layers, 32))\n",
    "    net['relu5_3'] = relu_layer('relu5_3', net['conv5_3'], b=get_bias(vgg_layers, 32))\n",
    "\n",
    "    net['conv5_4'] = conv_layer('conv5_4', net['relu5_3'], W=get_weights(vgg_layers, 34))\n",
    "    net['relu5_4'] = relu_layer('relu5_4', net['conv5_4'], b=get_bias(vgg_layers, 34))\n",
    "\n",
    "    net['pool5']   = pool_layer('pool5', net['relu5_4'])\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_loss_function = 1\n",
    "\n",
    "def content_layer_loss(p, x):\n",
    "    _, h, w, d = p.get_shape()\n",
    "    M = h.value * w.value\n",
    "    N = d.value\n",
    "    if content_loss_function   == 1:\n",
    "        K = 1. / (2. * N**0.5 * M**0.5)\n",
    "    elif content_loss_function == 2:\n",
    "        K = 1. / (N * M)\n",
    "    elif content_loss_function == 3:  \n",
    "        K = 1. / 2.\n",
    "    loss = K * tf.reduce_sum(tf.pow((x - p), 2))\n",
    "    return loss\n",
    "\n",
    "def sum_content_losses(sess, net, content_img):\n",
    "    sess.run(net['input'].assign(content_img))\n",
    "    content_loss = 0.\n",
    "    for layer, weight in zip(content_layers, content_layer_weights):\n",
    "        p = sess.run(net[layer])\n",
    "        x = net[layer]\n",
    "        p = tf.convert_to_tensor(p)\n",
    "        content_loss += content_layer_loss(p, x) * weight\n",
    "    content_loss /= float(len(content_layers))\n",
    "    return content_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Style loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_layer_loss(a, x):\n",
    "    _, h, w, d = a.get_shape()\n",
    "    M = h.value * w.value\n",
    "    N = d.value\n",
    "    A = gram_matrix(a, M, N)\n",
    "    G = gram_matrix(x, M, N)\n",
    "    loss = (1./(4 * N**2 * M**2)) * tf.reduce_sum(tf.pow((G - A), 2))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def gram_matrix(x, area, depth):\n",
    "    F = tf.reshape(x, (area, depth))\n",
    "    G = tf.matmul(tf.transpose(F), F)\n",
    "    \n",
    "    return G\n",
    "\n",
    "def sum_style_losses(sess, net, style_imgs):\n",
    "    total_style_loss = 0.\n",
    "    weights = [1.0]\n",
    "    \n",
    "    for img, img_weight in zip(style_imgs, weights):\n",
    "        sess.run(net['input'].assign(img))\n",
    "        style_loss = 0.\n",
    "\n",
    "        for layer, weight in zip(style_layers, style_layer_weights):\n",
    "            a = sess.run(net[layer])\n",
    "            x = net[layer]\n",
    "            a = tf.convert_to_tensor(a)\n",
    "            style_loss += style_layer_loss(a, x) * weight\n",
    "            \n",
    "        style_loss /= float(len(style_layers))\n",
    "        total_style_loss += (style_loss * img_weight)\n",
    "        \n",
    "    total_style_loss /= float(len(style_imgs))\n",
    "    \n",
    "    return total_style_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils and io functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    # bgr image\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    check_image(img, path)\n",
    "    img = img.astype(np.float32)\n",
    "    img = preprocess(img)\n",
    "    return img\n",
    "\n",
    "def write_image(path, img):\n",
    "    img = postprocess(img)\n",
    "    cv2.imwrite(path, img)\n",
    "\n",
    "def preprocess(img):\n",
    "    # bgr to rgb\n",
    "    img = img[...,::-1]\n",
    "    # shape (h, w, d) to (1, h, w, d)\n",
    "    img = img[np.newaxis,:,:,:]\n",
    "    img -= np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n",
    "    return img\n",
    "\n",
    "def postprocess(img):\n",
    "    img += np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n",
    "    # shape (1, h, w, d) to (h, w, d)\n",
    "    img = img[0]\n",
    "    img = np.clip(img, 0, 255).astype('uint8')\n",
    "    # rgb to bgr\n",
    "    img = img[...,::-1]\n",
    "    return img\n",
    "\n",
    "def read_flow_file(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        # 4 bytes header\n",
    "        header = struct.unpack('4s', f.read(4))[0]\n",
    "        # 4 bytes width, height    \n",
    "        w = struct.unpack('i', f.read(4))[0]\n",
    "        h = struct.unpack('i', f.read(4))[0]   \n",
    "        flow = np.ndarray((2, h, w), dtype=np.float32)\n",
    "        for y in range(h):\n",
    "            for x in range(w):\n",
    "                flow[0,y,x] = struct.unpack('f', f.read(4))[0]\n",
    "                flow[1,y,x] = struct.unpack('f', f.read(4))[0]\n",
    "    return flow\n",
    "\n",
    "def read_weights_file(path):\n",
    "    lines = open(path).readlines()\n",
    "    header = list(map(int, lines[0].split(' ')))\n",
    "    w = header[0]\n",
    "    h = header[1]\n",
    "    vals = np.zeros((h, w), dtype=np.float32)\n",
    "    for i in range(1, len(lines)):\n",
    "        line = lines[i].rstrip().split(' ')\n",
    "        vals[i-1] = np.array(list(map(np.float32, line)))\n",
    "        vals[i-1] = list(map(lambda x: 0. if x < 255. else 1., vals[i-1]))\n",
    "    # expand to 3 channels\n",
    "    weights = np.dstack([vals.astype(np.float32)] * 3)\n",
    "    return weights\n",
    "\n",
    "def normalize(weights):\n",
    "    denom = sum(weights)\n",
    "    if denom > 0.:\n",
    "        return [float(i) / denom for i in weights]\n",
    "    else: return [0.] * len(weights)\n",
    "\n",
    "def maybe_make_directory(dir_path):\n",
    "    if not os.path.exists(dir_path):  \n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "def check_image(img, path):\n",
    "    if img is None:\n",
    "        raise OSError(errno.ENOENT, \"No such file\", path)\n",
    "        \n",
    "def get_content_image(content_img):\n",
    "    path = os.path.join('./', content_img)\n",
    "      # bgr image\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    check_image(img, path)\n",
    "    img = img.astype(np.float32)\n",
    "    h, w, d = img.shape\n",
    "    mx = 512\n",
    "    # resize if > max size\n",
    "    if h > w and h > mx:\n",
    "        w = (float(mx) / float(h)) * w\n",
    "        img = cv2.resize(img, dsize=(int(w), mx), interpolation=cv2.INTER_AREA)\n",
    "    if w > mx:\n",
    "        h = (float(mx) / float(w)) * h\n",
    "        img = cv2.resize(img, dsize=(mx, int(h)), interpolation=cv2.INTER_AREA)\n",
    "    img = preprocess(img)\n",
    "    return img\n",
    "\n",
    "def get_style_images(content_img, style_images):\n",
    "    _, ch, cw, cd = content_img.shape\n",
    "    style_imgs = []\n",
    "    for style_fn in style_images:\n",
    "        path = os.path.join('./', style_fn)\n",
    "        # bgr image\n",
    "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "        check_image(img, path)\n",
    "        img = img.astype(np.float32)\n",
    "        img = cv2.resize(img, dsize=(cw, ch), interpolation=cv2.INTER_AREA)\n",
    "        img = preprocess(img)\n",
    "        style_imgs.append(img)\n",
    "    return style_imgs\n",
    "\n",
    "def get_noise_image(noise_ratio, content_img):\n",
    "    np.random.seed(10)\n",
    "    noise_img = np.random.uniform(-20., 20., content_img.shape).astype(np.float32)\n",
    "    img = noise_ratio * noise_img + (1. - noise_ratio) * content_img\n",
    "    return img\n",
    "\n",
    "def convert_to_original_colors(content_img, stylized_img):\n",
    "    content_img  = postprocess(content_img)\n",
    "    stylized_img = postprocess(stylized_img)\n",
    "    if color_convert_type == 'yuv':\n",
    "        cvt_type = cv2.COLOR_BGR2YUV\n",
    "        inv_cvt_type = cv2.COLOR_YUV2BGR\n",
    "    elif color_convert_type == 'ycrcb':\n",
    "        cvt_type = cv2.COLOR_BGR2YCR_CB\n",
    "        inv_cvt_type = cv2.COLOR_YCR_CB2BGR\n",
    "    elif color_convert_type == 'luv':\n",
    "        cvt_type = cv2.COLOR_BGR2LUV\n",
    "        inv_cvt_type = cv2.COLOR_LUV2BGR\n",
    "    elif color_convert_type == 'lab':\n",
    "        cvt_type = cv2.COLOR_BGR2LAB\n",
    "        inv_cvt_type = cv2.COLOR_LAB2BGR\n",
    "    content_cvt = cv2.cvtColor(content_img, cvt_type)\n",
    "    stylized_cvt = cv2.cvtColor(stylized_img, cvt_type)\n",
    "    c1, _, _ = cv2.split(stylized_cvt)\n",
    "    _, c2, c3 = cv2.split(content_cvt)\n",
    "    merged = cv2.merge((c1, c2, c3))\n",
    "    dst = cv2.cvtColor(merged, inv_cvt_type).astype(np.float32)\n",
    "    dst = preprocess(dst)\n",
    "    return dst\n",
    "\n",
    "def write_image_output(output_img, content_img, style_imgs, init_img):\n",
    "    out_dir = './'\n",
    "    maybe_make_directory(out_dir)\n",
    "    img_path = os.path.join(out_dir, output_name)\n",
    "    content_path = os.path.join(out_dir, 'content.png')\n",
    "    init_path = os.path.join(out_dir, 'init.png')\n",
    "\n",
    "    write_image(img_path, output_img)\n",
    "    write_image(content_path, content_img)\n",
    "    write_image(init_path, init_img)\n",
    "    index = 0\n",
    "    for style_img in style_imgs:\n",
    "        path = os.path.join(out_dir, 'style_'+str(index)+'.png')\n",
    "        write_image(path, style_img)\n",
    "        index += 1\n",
    "    \n",
    "    # save the configuration settings\n",
    "    out_file = os.path.join(out_dir, 'meta_data.txt')\n",
    "    f = open(out_file, 'w')\n",
    "    f.write('image_name: {}\\n'.format(output_name))\n",
    "    f.write('content: {}\\n'.format(content_img))\n",
    "    index = 0\n",
    "    for style_img, weight in zip(style_imgs, [1.0]):\n",
    "        f.write('styles['+str(index)+']: {} * {}\\n'.format(weight, style_img))\n",
    "        index += 1    \n",
    "    f.write('content_weight: {}\\n'.format(content_weight))\n",
    "    f.write('style_weight: {}\\n'.format(style_weight))\n",
    "    f.write('tv_weight: {}\\n'.format(tv_weight))\n",
    "    f.write('content_layers: {}\\n'.format(content_layers))\n",
    "    f.write('style_layers: {}\\n'.format(style_layers))\n",
    "    f.write('optimizer_type: {}\\n'.format(optimizer_to_use))\n",
    "    f.write('max_iterations: {}\\n'.format(max_iterations))\n",
    "    f.close()\n",
    "    \n",
    "def get_noise_image(noise_ratio, content_img):\n",
    "    # np.random.seed(args.seed)\n",
    "    noise_img = np.random.uniform(-20., 20., content_img.shape).astype(np.float32)\n",
    "    img = noise_ratio * noise_img + (1.-noise_ratio) * content_img\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Style transfer algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stylize(content_img, style_imgs, init_img):\n",
    "    with tf.device('/gpu:0'), tf.Session() as sess:\n",
    "        net = build_model(content_img)\n",
    "        \n",
    "        L_style = sum_style_losses(sess, net, style_imgs)\n",
    "        L_content = sum_content_losses(sess, net, content_img)\n",
    "        L_tv = tf.image.total_variation(net['input'])\n",
    "        \n",
    "        alpha = content_weight\n",
    "        beta  = style_weight\n",
    "        theta = tv_weight\n",
    "        \n",
    "        L_total  = alpha * L_content + beta * L_style + theta * L_tv\n",
    "        \n",
    "        optimizer = get_optimizer(L_total)\n",
    "\n",
    "        if optimizer_to_use == 'adam':\n",
    "            minimize_with_adam(sess, net, optimizer, init_img, L_total)\n",
    "        elif optimizer_to_use == 'lbfgs':\n",
    "            minimize_with_lbfgs(sess, net, optimizer, init_img)\n",
    "        \n",
    "        output_img = sess.run(net['input'])\n",
    "        \n",
    "        if original_colors:\n",
    "            output_img = convert_to_original_colors(np.copy(content_img), output_img)\n",
    "\n",
    "        write_image_output(output_img, content_img, style_imgs, init_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_with_lbfgs(sess, net, optimizer, init_img):\n",
    "    if True: print('\\nMINIMIZING LOSS USING: L-BFGS OPTIMIZER')\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    sess.run(net['input'].assign(init_img))\n",
    "    optimizer.minimize(sess)\n",
    "\n",
    "def minimize_with_adam(sess, net, optimizer, init_img, loss):\n",
    "    if True: print('\\nMINIMIZING LOSS USING: ADAM OPTIMIZER')\n",
    "    train_op = optimizer.minimize(loss)\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    sess.run(net['input'].assign(init_img))\n",
    "    iterations = 0\n",
    "    while (iterations < max_iterations):\n",
    "        sess.run(train_op)\n",
    "        if iterations % 25 == 0 or iterations == max_iterations - 1:\n",
    "            curr_loss = loss.eval()\n",
    "            print(\"At iterate {}\\tf=  {}\".format(iterations, curr_loss))\n",
    "        iterations += 1\n",
    "\n",
    "def get_optimizer(loss):\n",
    "    print_iterations = 25\n",
    "    if optimizer_to_use == 'lbfgs':\n",
    "        optimizer = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "            loss, method='L-BFGS-B',\n",
    "            options={'maxiter': max_iterations, 'disp': print_iterations})\n",
    "    elif optimizer_to_use == 'adam':\n",
    "        optimizer = tf.train.AdamOptimizer(1)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_weight = 5e1;\n",
    "style_weight = 1e4;\n",
    "tv_weight = 1e0;\n",
    "\n",
    "style_layers = ['relu1_1', 'relu2_1', 'relu3_1', 'relu4_1', 'relu5_1']\n",
    "style_layer_weights = [0.2, 0.2, 0.2, 0.2, 0.2]\n",
    "\n",
    "content_layers = ['conv5_2']\n",
    "content_layer_weights = [1]\n",
    "\n",
    "optimizer_to_use = 'lbfgs'\n",
    "optimizer_to_use = 'adam'\n",
    "\n",
    "max_iterations = 1000\n",
    "\n",
    "original_colors = False\n",
    "color_convert_type = 'luv'\n",
    "\n",
    "content_image_name = 'nice/cabelo.jpg'\n",
    "style_image_name = 'images/starry-night.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- RENDERING SINGLE IMAGE ----\n",
      "\n",
      "\n",
      "BUILDING VGG-19 NETWORK\n",
      "loading model weights...\n",
      "constructing layers...\n",
      "LAYER GROUP 1\n",
      "--conv1_1 | shape=(1, 512, 288, 64) | weights_shape=(3, 3, 3, 64)\n",
      "--conv1_2 | shape=(1, 512, 288, 64) | weights_shape=(3, 3, 64, 64)\n",
      "LAYER GROUP 2\n",
      "--conv2_1 | shape=(1, 256, 144, 128) | weights_shape=(3, 3, 64, 128)\n",
      "--conv2_2 | shape=(1, 256, 144, 128) | weights_shape=(3, 3, 128, 128)\n",
      "LAYER GROUP 3\n",
      "--conv3_1 | shape=(1, 128, 72, 256) | weights_shape=(3, 3, 128, 256)\n",
      "--conv3_2 | shape=(1, 128, 72, 256) | weights_shape=(3, 3, 256, 256)\n",
      "--conv3_3 | shape=(1, 128, 72, 256) | weights_shape=(3, 3, 256, 256)\n",
      "--conv3_4 | shape=(1, 128, 72, 256) | weights_shape=(3, 3, 256, 256)\n",
      "LAYER GROUP 4\n",
      "--conv4_1 | shape=(1, 64, 36, 512) | weights_shape=(3, 3, 256, 512)\n",
      "--conv4_2 | shape=(1, 64, 36, 512) | weights_shape=(3, 3, 512, 512)\n",
      "--conv4_3 | shape=(1, 64, 36, 512) | weights_shape=(3, 3, 512, 512)\n",
      "--conv4_4 | shape=(1, 64, 36, 512) | weights_shape=(3, 3, 512, 512)\n",
      "LAYER GROUP 5\n",
      "--conv5_1 | shape=(1, 32, 18, 512) | weights_shape=(3, 3, 512, 512)\n",
      "--conv5_2 | shape=(1, 32, 18, 512) | weights_shape=(3, 3, 512, 512)\n",
      "--conv5_3 | shape=(1, 32, 18, 512) | weights_shape=(3, 3, 512, 512)\n",
      "--conv5_4 | shape=(1, 32, 18, 512) | weights_shape=(3, 3, 512, 512)\n",
      "\n",
      "MINIMIZING LOSS USING: ADAM OPTIMIZER\n",
      "At iterate 0\tf=  [3.0181327e+11]\n",
      "At iterate 25\tf=  [8.83241e+10]\n",
      "At iterate 50\tf=  [3.8961725e+10]\n",
      "At iterate 75\tf=  [2.0440414e+10]\n",
      "At iterate 100\tf=  [1.2402074e+10]\n",
      "At iterate 125\tf=  [8.643424e+09]\n",
      "At iterate 150\tf=  [6.574185e+09]\n",
      "At iterate 175\tf=  [5.2885146e+09]\n",
      "At iterate 200\tf=  [4.410923e+09]\n",
      "At iterate 225\tf=  [3.7688067e+09]\n",
      "At iterate 250\tf=  [3.2730788e+09]\n",
      "At iterate 275\tf=  [2.8781489e+09]\n",
      "At iterate 300\tf=  [2.553226e+09]\n",
      "At iterate 325\tf=  [2.284765e+09]\n",
      "At iterate 350\tf=  [2.0599846e+09]\n",
      "At iterate 375\tf=  [1.8696453e+09]\n",
      "At iterate 400\tf=  [1.7066231e+09]\n",
      "At iterate 425\tf=  [1.5659813e+09]\n",
      "At iterate 450\tf=  [1.443745e+09]\n",
      "At iterate 475\tf=  [1.3362743e+09]\n",
      "At iterate 500\tf=  [1.2417848e+09]\n",
      "At iterate 525\tf=  [1.1579291e+09]\n",
      "At iterate 550\tf=  [1.083552e+09]\n",
      "At iterate 575\tf=  [1.01734086e+09]\n",
      "At iterate 600\tf=  [9.58133e+08]\n",
      "At iterate 625\tf=  [9.052607e+08]\n",
      "At iterate 650\tf=  [8.576384e+08]\n",
      "At iterate 675\tf=  [8.144987e+08]\n",
      "At iterate 700\tf=  [7.751583e+08]\n",
      "At iterate 725\tf=  [7.3908166e+08]\n",
      "At iterate 750\tf=  [7.0581114e+08]\n",
      "At iterate 775\tf=  [6.751314e+08]\n",
      "At iterate 800\tf=  [6.466909e+08]\n",
      "At iterate 825\tf=  [6.203204e+08]\n",
      "At iterate 850\tf=  [5.957893e+08]\n",
      "At iterate 875\tf=  [5.7275866e+08]\n",
      "At iterate 900\tf=  [5.511623e+08]\n"
     ]
    }
   ],
   "source": [
    "time_string = datetime.datetime.fromtimestamp(time.time()).strftime('%m_%d_%H_%M_%S')\n",
    "random_string = ''.join(random.choices(string.ascii_uppercase + string.digits, k=6))\n",
    "output_name = 'out_%s_%s.png' % (time_string, random_string)\n",
    "\n",
    "content_img = get_content_image(content_image_name)\n",
    "style_imgs = get_style_images(content_img, [style_image_name])\n",
    "with tf.Graph().as_default():\n",
    "    print('\\n---- RENDERING SINGLE IMAGE ----\\n')\n",
    "    init_img = get_noise_image(1.0, content_img)\n",
    "    tick = time.time()\n",
    "    stylize(content_img, style_imgs, init_img)\n",
    "    tock = time.time()\n",
    "    print('Single image elapsed time: {}'.format(tock - tick))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
